# info

* MSA (Microservice Architecture)
    1. 장점: 서비스별 확장성/유연한 배포/어플리케이션 로직 분리 및 여러개 어플리케이션 으로 나눠서 서비스화/데이터(소스 및 디비) 분산/팀간의 의존성 제거/
    2. 단점: 네트워크 홉 증설/스프링 프레임웍과 같은 공통 라이브러리도 각각 필요하기 때문에, 배포하고자 하는 서비스의 수 만큼 중복된 양의 메모리가 필요하게 된다./기술의 다양성으로 인한 기술 스택 향상/테스팅의 복잡성 향상/
    3. 중요 - 트렌젝션 보장이 어려움(MSA형태 자체가 트렌젝션을 보장하는 아키텍처 라기보다는 대용량 처리가 필요한 B2C형태에 적합)

* 모노리틱 아키텍쳐(Monolithic Architecture) 기존에 정통적인 통짜 구조의 아키텍처
    1. 장점: 규모가 작을 경우에는 애플리케이션 배포 용이 (규모가 클 경우에도 컴퍼넌트 호출 제약이 덜하면 운영관리 용이, 하나의 형태로 트렌젝션 관리등이 용이)
    2. 단점: 한두명의 실수가 전체 서비스에 영향/서비스가 커질 수록 협업의 어려움

* 프로세스 vs 쓰레드
    1. 프로세스
        1. 컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램
        2. 메모리에 올라와 실행되고 있는 프로그램
        3. 운영체제로 부터 시스템 자원을 할당받은 작업단위
        4. code, data, stack, heap의 구조로 되어있는 독립적 메모리 영역
        5. 프로세스는 각각 독립된 메모리 영역(Code, Data, Stack, Heap의 구조)을 할당받는다.
        6. 기본적으로 프로세스당 최소 1개의 스레드(메인 스레드)를 가지고 있다.
        7. 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다.
        8. 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신(IPC) 사용한다.
    2. 쓰레드
        1. 프로세스에서 실행되는 여러 흐름단위
        2. 프로세스의 특정한 수행 경로
        3. 프로세스가 할당받은 자원을 이용한 실행 단위
        4. 쓰레드는 Stack영역만 할당받고 나머지는 영역은 공유한다,.
        5. 스레드는 한 프로세스 내에서 동작되는 여러 실행의 흐름으로, 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행된다.
        6. 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유한다. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없다.
        7. 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있다.
        8. 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드(sibling thread)도 그 변경 결과를 즉시 볼 수 있다.

* 애자일 방법론 간단 정의 (협력과 피드백을 자주 더 잘하는것!)
* 테스트 주도 개발 (Test Driven Development) 테스트 코드르 볼 경우에 소스코드에 대한 이해가 되며, 수정 등의 자신감이 생긴다.
    1. 장점: 코드복잡도가 줄어든다./코드 결함이 줄어든다
    2. 단점: 개발방식의 변경/하나의 코드를 테스트 코드 하나를 더 만들어야 하는 시간적 문제/개발 시간 증가로 인한 테스트 비용증가

* Git VS SVN
    1. 저장소의 위치로 인한 커밋 속도 차이 (git=내컴퓨터/SVN=서버)
    2. 커밋에 스테이징 영역이 Git에만 있음.
    3. 브런치 활용 (Git=내려받을 필요없으며, 병합도 간단)

* 트래픽의 과부하 발생시 대처 방안.
    1. 실시간 적용이 가능한 부분 확인.
        1. 네트워크 대역폭 제한 및 제한된 설정 확인.
        2. CDN 및 웹캐시 적용 여부 확인
        3. 정상 트래픽 유무 확인.
            1. 시스템 크론 및 부하 발생 최소화
            2. 프로세스 및 시스템 log 확인.
            3. 네트워크 TIME_WAIT 확인
    2. 시간적 조치가 가능한 처리 내역 정리.
        1. 로드밸런싱 (캐시)
        2. 서버 리소스 증설
        3. 서버 추가 구성
        4. 부하 서비스 분리

* 스위치 각 특징 및 장단점
1. L2
```
- L2 스위치로 가장 흔히 볼 수 있는 스위치 방식이며 다른 방식에 비해 저렴하다
- 패킷의 MAC 주소를 읽어 스위칭을 하고, MAC의 OSI 계층 중 2계층에 해당하기 때문에 Layer 2 스위치라 한다.
- 기본적인 동작은 브리지나 스위칭 허브는 모든 자료를 보내는 곳으로 수신 번지를 전송한다
- 브리지는 어떤 포트에서 받은 데이터를 다른 포트로 전송하나 L2 스위치 허브에서는 여러개의 포트 중 특정 포트로만 전송한다

동작 원리 

- 다른 스위치 처럼 프로세서, 메모리, 펌웨어(OS)가 담겨 있는 FLASH ROM으로 구성됨
- 부팅이 되면 L2스위치는 각 포트별로 연결되어 있는 노드의 상태를 확인한다
- 각 노드의 MAC 주소를 알아내서 이것을 메모리에 적재하게 되고, 패킷이 전달될 때 이 정보를 바탕으로 스위칭하게 된다
- 스위치의 운영체제가 적재되거나 스위칭시 각 포트별 주소 정보가 저장된다(스위칭 허브 메모리)
- 스위칭 허브를 선택할 때 스위칭 허브가 얼마만큼의 메모리와 어느 정도의 주소 테이블을 저장할 수 있는지를 확인한다
- 보통의 스위치는 메모리 용량 이상의 주소가 저장될 경우(연결 노드가 많은 경우) 스위칭 기능이 중지되고, 더미 허브와 같은 방식으로 동작한다

장점 : 구조가 간단 신뢰성이 높다 / 가격이 저렴하고 성능이 좋다
단점 : Broadcast패킷에 의해 성능 저하가 발생한다 / 라우팅이 불가능 / 상위 레이어 프로토콜을 이용한 스위칭이 불가능하다
```
2. L3
```
- L3 스위치로 포트간 패킷 스위칭을 위해 패킷의 IP나 IPX 주소를 읽어서 스위칭을 하며 통신 경로를 한번만 설정한다
- 해당 프로토콜을 쓰는 패킷에 대해 스위칭이 가능하며, IP나 IPX주소가 OSI 7계층 중 3계층에 해당하기 때문에 Layer 3 스위치라 한다
- L2 스위치에 라우팅(Routing) 기능을 추가하고 대부분 고성능H/W를 기초로 함 L2와 기본구성 동일

동작 원리

- 부팅 시 각 포트로 연결된 노드의 상태를 확인하고 노드의 주소를 테이블의 메모리에 적재하여 패킷이 전달될 때 이 정보를 바탕으로 스위칭을 한다
- L3는 L2에 비해 고급 기능을 지원하므로 L2는 일부 고급기종에서만 스위치에 IP주소를 할당하지만 L3는 기본적으로 스위치 자체에 IP주소를 할당한다
- 각 포트별 IP 주소 할당 내역등을 설정하여 스위칭할 때 설정된 값을 이용한다 - 기본설정모드 지원

장점 : Broadcast트래픽으로 전체 성능 저하 방지 / 트래픽 체크, 가상 랜 등의 많은 부가 기능 가짐
단점 : 특정 프로토콜을 이용해야 스위칭할 수 있다 / 대부분의 트래픽이 서브넷의 한계를 넘는다
```
3. L4
```
- L3와 같이 프로토콜을 기반으로 하며, 어플리케이션별로 우선 순위를 두어 스위칭이 가능하다
- 여러대의 서버를 1대처럼 묶을 수 있는 부하 분산(Load Balancing) 기능을 제공한다 
- 많은 양의 트래픽을 여러 서버로 분산 가능
- 각 제조 업체별로 설정 방법 및 제공 기능이 다르므로 특별한 표준 지정이 힘듬 

동작 원리

- L3 스위치와 유사한 구조와 동작 원리를 갖고 있지만 가상 랜 기능과 그룹화, 부하 분산 등의 고급 설정이 추가로 포함되는 점이 다르다
- TCP/IP 프로토콜을 기반으로 동작하는 것이 대부분이며 포트 번호를 이용한 스위칭까지도 가능하다
- 포트 번호는 수신 컴퓨터에서 IP 패킷의 형태로 결정하여 상위 계층으로 전달한다

장점 : 보안성이 높고 고급 스위칭 설정이 가능하다 / 상황에 적절한 설정 / 용량에 관계 없이 네트워크의 성능 개선에 기여한다
단점 : 프로토콜에 의존적이며 설정이 복잡하다 / 고가의 장비로 L2, L3 스위치와 적잘한 혼합 배치가 필요하다.
```
4. 간단정리
```
L2 스위치는 MAC 정보(MAC Table)를 보고 스위칭을 하는 것이고,(일반적인 스위치의 기능)

L3 스위치는 IP 정보(Routing Table)를 보고 스위칭을 하는 것이고,(라우팅 기능이 추가됨)

L4 스위치는 IP+Port(Session or Connection)를 보고 스위칭을 하는 것이며,(로드밸런싱을 위해 사용됨)

L7 스위치는 실제 App 데이터(Content)를 보고 스위칭을 하는 것
```
5. 용어 설명
```
유니캐스트(Unicast) 란,
MAC 기반으로 상대측 IP주소를 목적지로하는 일대일 통신방식

브로드캐스트(Broadcast) 란,
자신의 호스트가 속해 있는 네트워크 전체를 대상으로 패킷을 전송하는 일대다 통신방식 이다.
브로드캐스트는 로컬 랜 상에 붙어있는 모든 네트워크 장비들에게 보내는 통신이다

멀티캐스트(Multicast) 란,
멀티캐스트 전송방식은 하나 이상의 송신자들이 특정한 하나 이상의 수신자들에게 데이터를 전송하는 방식
```

* ipv4 / ipv6
    1. ipv4 -> 32bit
    2. ipv6 -> 128bit

* DNS recursive (리퀼시브) / iterative (인터레이티브)
    1. recursive -> DNS 서버 찾으라고함. (클라이언트에 최종 결과값만을 반환 합니다.)
    2. iterative -> 자신이 관리하고 있지 않은 질의 요청이 있을 경우 질의응답이 가능한 NS 목록응답한다. (클라이언트랑 계속 핑퐁)
* DNS 추가 설명
    1. 네임서버 캐싱 -> 반복 작업및 불필요한 요청 제거를 위한 DNS메시지 트래픽을 감소 시킨다. (TTL => 유효기간/RTT => 네임서버 왕복시간 동일 영역관리 서버가 여러대일 경우 RTT값이 가장 작은 서버로 질의)

* BGP
    1. BGP는 Dynaminc Routing Protocol 중 하나로 Border Gateway 역할
    2. BGP 라우팅 프로토콜은 보통 SP나 ISP간, 그리고 국제망 또는 대기업 등에서 소유한 BGP AS Number로 연동
* 용어 설명
    1. AS -> 단일 관리자 집단에서 관리할수 있는 네트워크 영역
    2. IBGP = 동일한 AS 에 속해 있는 라우터
    3. eBGP = 서로 다른 AS 에 속해 있는 라우터

* apache + tomcat 연동 이유
    1. 개발시에는 톰캣만으로도 웹서버 역할을 하는데 충분하지만 운영 시에는 아파치+톰캣을 연동해주는 것이 성능에 더 유리하다(HTML 파일/이미지 파일과 JSP 파일의 처리 분산)
    2.  그 이유로는 정적 데이터를 처리할 때 아파치의 성능이 더 좋다->image나 css같은 정적 데이터는 아파치에서 처리하고 톰캣은 동적 페이지 생성에 주력하는게 효율면에서 좋다

* web / was
```
WEB 서버

Web 서버는  클라이언트가 웹 브라우저에서 서버에 페이지 요청을 하면 Web 서버에서 요청을 받아 정적 페이지(.html .jpeg .css 등..) 컨텐츠를 제공하는 서버 
대표적인 WEB서버에는  Apache, NGINX 와 Windows 전용 Web 서버 인  IIS 가 있음

WAS 서버 (Web Application Server)

html 만으로는 할 수 없는 데이터베이스 조회나 다양한 로직처리 같은 동적인 컨텐츠를 제공하기 위해 만들어진 어플리케이션 서버
대표적인 WAS에는 Tomcat, Jeus, JBoss, Web Sphere 등이 있음
```
* apache / nginx 차이점
    * 특징이라면 Event Driven 방식을 꼽을수 있을것 같다. Event Driven 방식에 대해 잠깐 언급을 하고 넘어가면 요청이 들어오면 어떤 동작을 해야하는지만 알려주고 다른요청을 처리하는 방식이다. (Producer Consumer Pattern과 유사하다.) 그러다보니 프로세스를 fork하거나 쓰레드를 사용하는 아파치와는 달리 CPU와 관계없이 모든 IO들을 전부 Event Listener로 미루기 때문에 흐름이 끊기지 않고 응답이 빠르게 진행이 되어 1개의 프로세스로 더 빠른 작업이 가능하게 될수 있다. 이때문에 메모리적인 측면에서 Nginx가 System Resource를 적게 처리한다는 장점이 있다고 한다.
    * 각 커텍션 마다 프로세스 쓰레드 복제 하지않는다 해당 부분으로 부하가 증가해도 CPU 및 메모리 사용량이 크게 증가하지 않는다.
        * apache 의 경우 Prefork MPM방식으로 요청하나당 프로세스 및 쓰레드 기반으로 동작 (apache 2.4.X 부처는  event MPM 방식이 기본 모듈이지만 자원사용 측면에서는 nginx 보다 부족)

* tcp ip close
![link](/images/tcp-cloes1.png)
1. 통신을 종료하고자 하는 Client가 서버에게 FIN 패킷을 보내고 자신은 FIN_WAIT_1 상태로 대기한다.
2. FIN 패킷을 받은 서버는 해당 포트를 CLOSE_WAIT으로 바꾸고 잘 받았다는 ACK 를 Client에게 전하고 ACK를 받은 Client는 상태를 FIN_WAIT_2로 변경한다.
그와 동시에 Server에서는 해당 포트에 연결되어 있는 Application에게 Close()를 요청한다.
3. Close() 요청을 받은 Application은 종료 프로세스를 진행시켜 최종적으로 close()가 되고 server는 FIN 패킷을 Client에게 전송 후 자신은 LAST_ACK 로 상태를 바꾼다.
4. FIN_WAIT_2 에서 Server가 연결을 종료했다는 신호를 기다리다가 FIN 을 받으면 받았다는 ACK를 Server에 전송하고 자신은 TIME_WAIT 으로 상태를 바꾼다. (TIME_WAIT 에서 일정 시간이 지나면 CLOSED 되게 된다.)
최종 ACK를 받은 서버는 자신의 포트도 CLOSED로 닫게 된다.

![link](/images/tcp-cloes2.png)

* CLOSE_WAIT 원인
```
쓰레드가 검색 결과를 받아오지 못하고 대기중(WAITING)인 것을 확인했습니다. 그런데 재밌게도 이 검색 결과는 로컬에서 받아오는 것입니다. 즉, 로컬은 행업 상태여서 검색 결과를 보내주지 못하는 상황이고, 쓰레드는 검색 결과를 받기 위해 대기하는 상황입니다.

원래 일정 시간이 경과하면 타임아웃으로 끊어야 하는데, 행업 상태에 빠지다보니 이 조차도 처리되지 않고 서로가 서로를 기다리는 상황인 거죠.

즉, 보낼 수도 없고 받을 수도 없는 일종의 교착 상태(deadlock)가 원인으로 지목됐습니다. 아울러 이 상태는 성능 테스트가 끝나도 정상으로 복구되지 않았습니다.
1. 파일서버가 필요해 별도 웹 서버를 구성하지 않고 톰캣의 /ROOT를 이용
2. Static HTML 파일을 올려두고 톰캣에서 구동중인 웹앱의 HttpClient에서 로컬 자기 자신(동일한 톰캣)을 호출해 HTML을 받아가도록 구성
3. 그러나, 부하를 높이니 점점 느려지다 HTML 조차 내려주지 못하는 행업 상태 발생
4. 모든 소켓이 CLOSE_WAIT 상태에 빠짐

요청과 응답을 받는 과정에서 recursive 한 호출이 교착 상태의 원인이었으며 별도 서버를 구성하여 상호 의존성 없이 호출 가능하도록 구성했다. 톰캣을 통한 동일한 WAS가 아닌, 별도의 nginx를 구성하고 다른 프로세스에서 HTML 파일을 내려주도록 처리해 문제를 해결했습니다.

테스트 결과, 더 이상 문제가 발생하지 않음을 확인했습니다.
```
* TIME_WAIT 원인 및 해결 (성능 저하 이슈는 20년전 기록이며, 성능 저하는 미비하다)
```
- 클라이언트가 서버 투 서버로 한 서버에 요청이 많을 경우 tcp_tw_reuse 옵션을 설정해 TIME_WAIT을 재사용하도록 한다. 서버는 해당 사항이 없다.(그외에는 굳이 TIME_WAIT를 건드릴 이유는 없다.)
$ echo 1 > /proc/sys/net/ipv4/tcp_tw_reuse
$ sysctl net.ipv4.tcp_tw_reuse
net.ipv4.tcp_tw_reuse = 1
```
* TIME_WAIT을 가장 효율적으로 재활용 하는 방법은 지금 소개하는 net.ipv4.tcp_tw_recycle 옵션이지만, NAT 환경에서 문제가 있습니다.5 서버가 로드 밸런서 뒤에 위치하는 서비스 환경에선 장비간 타임스탬프가 일치하지 않아 역전 현상이 발생하면 패킷 드롭이 발생할 수 있으므로 사용하면 안됩니다

* AWS, Azure, GCP
    * AWS 장점: 전세계적인 높은 점유율/성숙한 제품/광범위한 서비스 교육
    * AWS 단점: 어려운 비용 관리
    * Azure 장점: MS제품군에 대한 호환성/하이브리드 클라우드 운영가능(회사의 AD연동 등.)
    * Azure 단점: 통합적 관리도구 불충분/기술지원 및 커뮤니케이션 문제
    * GCP 장점: 클라우드 친화적인 비지니스 디자인/전문적인 DevOps 보유/오픈소스 호환성 중심/높은 컴퓨터 오퍼링과 혁신기능
    * GCP 단점: AWS 및 Azure에 비해 다양한 서비스 부족/전세계 데이터 센터 부족

* 가상화
    * 장점: 자원효율 극대화/에너지 절감 효과
* 클라우드
    * 장점: 인터넷을 매개로 하여 서비스 형태로 제공
* 가상화/클라우드 차이점
    * 비용/탄력성,확장성/가상화=기술,클라우드=방법론/보안성

* linux 파일,디렉토리 권한
```
drwxr-xr-x  2  root  root  4096 Apr 22 16:59 conory
(소유자 : rwx , 그룹 : r-x , 공개 : r-x)
r -> 읽기 / w -> 쓰기 / -> x 실행

파일Type 퍼미션정보 링크수 소유자 소유그룹 용량 생성날짜 파일이름
파일 Type : "d" -> 디렉토리 , "l" -> 링크파일 , "-" -> 일반파일 등등..
퍼미션정보 : 해당 파일에 어떠한 퍼미션이 부여되어있는 지 표시!
링크수 : 해당 파일이 링크된 수! 링크는 윈도우의 "바로가기"와 같습니다. "in [대상파일] [링크파일]" 명령으로 링크파일을 만듭니다.
소유자 : 해당 파일의 소유자이름! (누구껀지?)
소유그룹 : 해당 파일을 소유한 그룹이름! 특별한 변경이 없을 경우 소유자가 속한 그룹이 소유그룹으로 지정됩니다.
용량 : 파일의 용량
생성날짜 : 파일이 생성된 날짜
파일이름 : 파일이름
```

* 인프라/서비스 엔지니어링 및 장애상황 극복을 위한 방안
    * 빅샐러 지원/F2 DDos/Azure CPU 보안성 업데이트 일정 무시하고 진행한 부분 -> 자동화설정으로 대처
* 네트워크 및 서버에 대한 표준화 및 운영에 대한 표준 구성
    * 방화벽 장비에 대한 초기 구성은 기본정책이 전체 차단 이후에 조치 이나, 그렇지 않을 시스템에서의 재작업 과정에서의 네트워크 서버 에 대한 통신 정책 표준화 및 이후 운영에 대한 표준화를 위한 문서 작성 및 전자결제 양식 업데이트 및 절차 적용.
* 컨테이너 기반의 플랫폼 환경 구축 및 운영
    * 켄테이너 기반의 플랫폼에 대한 환경 구축을 테스트한 경험이 있으며, docker in docker 형식 및 docker out side docker 형식 확인 및 두가지 형식을 이용한 docker atuo bilud 환경 구축
* MSA 구성시 발견될수 있는 문제점
    * 운영을 진행할 경우에는 DNS 문제 및 MSA 서비스시에는 특정 서버군이 기존의 서버형태에서 클라이언트 형태로 변환되어 기존에 발견되지 않았던 문제등을 마주 할수 있다.
* 동시 접속량이 많은 서비스를 위한 분산 처리 아키텍처에 대한 경험
    * 빅샐러 부분이며, 이러한 부분은 AWS 클라우드를 접하게 되면서 조금더 세분화 되어서 진행하였습니다.

* Telegraf
    * 단일 바이너리로 배포 가능 (Go 제작으로 별도 의존성 설치 없이 지원 가능.)
        * Go 언어 특징 하나의 바이너리로 컴파일 가능/빠르다.

* YAML -> 가독성을 최우선으로 개발된 언어 (보이는 시각부분에서 매우 자연스러움)

* AMI 가상화 유형
    * PV(Para Virtualization, 반가상화: Para Virtualization(PV) 는 반가상화로 전가상화와는 달리 하드웨어를 완전히 가상화하지 않습니다. 하이퍼콜(Hyper Call)이라는 인터페이스로 직접 하이퍼바이저에게 요청을 날릴 수 있게 하여 성능이 빠르다는 장점이 있습니다. 하지만 게스트 운영체제가 하드웨어의 가상화 여부를 알고 있어야 하며, 필요한 경우 운영체제의 커널을 수정해야 합니다.
    * HVM(하드웨어 가상 머신): Hardware Virtual Machine (HVM)은 베어메탈 식의 가상화 타입입니다. 즉 호스트 운영체제 없이 하드웨어 상에 하이퍼바이저가 바로 설치되고, 그 위에 가상머신을 구현하는 전가상화의 일종으로 보면 되는데, 다른 guest OS와 완전히 독립되고 OS 수정없이 그대로 사용가능하다는 이점이 있습니다. 예전에는 퍼포먼스가 PV에 비해 떨어진다고 알려져 왔지만 AWS가 발전하면서 퍼포먼스 차이가 비슷하거나 더 좋은 성능을 내는 경우가 많아지게 되었습니다.

* Linux LVM
    * Logical Volume을 효율적이고 유연하게 관리하기 위한 커널의 한 부분이자 프로그램 이라고 할 수 있습니다. 기존방식이 파일시스템을 블록 장치에 직접 접근해서 읽고 쓰기를 했다면, LVM은 파일시스템이 LVM이 만든 가상의 블록 장치에 읽고 쓰기를 하게 됩니다.
        * PV(Physical Volume)
        * PE(Physical Extent)
        * VG(Volume Group)
        * LV(Logical Volume)
        * LE(Logical Extent)

![lvm-img](/images/lvm-img.png)

* iperf3
    * 인스턴스 별 네트워크 대역폭 측정 등에 사용

* 가상화 종류
    * 호스트 가상화 (호스트OS 위에 게스트 OS가 구동되는 방식)
        * 장점 : 가상의 하드웨어를 에뮬레이팅하기 때문에 호스트 운영체제에 크게 제약사항이 없음
        * 단점 : OS위에 OS가 얹히는 방식이기 때문에 오버헤드가 클 수 있음
    * 하이퍼바이저 (Host OS없이 하드웨어에 하이퍼바이저를 설치하여 사용하는 방식)
        * 장점 : 별도의 Host OS가 없기 때문에 오버헤드가 적고, 하드웨어를 직접 제어하기 때문에 효율적으로 리소스를 사용할 수 있음
        * 단점 : 자체적으로 머신에 대한 관리 기능이 없기 때문에 관리를 위한 컴퓨터나 콘솔이 필요함
            * 전가상화
                * 장점 : 하드웨어를 완전히 가상화하기 때문에 Guest OS 운영체제의 별다른 수정이 필요 없음
                * 단점 : 하이퍼바이저가 모든 명령을 중재하기 때문에 성능이 비교적 느림
            * 반가상화
                * 장점 : 모든 명령을 DOM0를 통해 하이퍼바이저에게 요청하는 전가상화에비해 성능이 빠름
                * 단점 : 하이퍼바이저에게 Hyper Call 요청을 할 수 있도록 각 OS의 커널을 수정해야하며 오픈소스 OS가 아니면 반가상화를 이용하기가 쉽지 않음
    * 컨테이너 (호스트 OS위에 컨테이너관리 소프트웨어를 설치하여 동작하는 방식)
        * 장점: 컨테이너 가상화는 오버헤드가 적어 가볍고 빠른 장점이 있음

* 클라우드로 마이그레이션 할 경우에 주의 사항
    * 클라우드 장애 가능성을 배제하지 마라 (이중화(넷플렉스의 카오스몽키))
    * 한번에, 동시에, 마이그레이션을 할수 있다는 생각을 버려라 (IDC <-> AWS 데이터 동기화 고려)
    * 클라우드 운영시 필요한 도구와 서비스를 개발할수 있어야 한다.
    * 클라우드 장애 발생을 인정하고, 탄력적으로 인프라를 설계
    * 자신이 없다면 클라우드와 데이터센터 2곳을 운영하려는 생각은 하지마라

* HTTP Method(메서드)
    * GET : 정보를 요청하기 위해서 사용한다. (SELECT)
    * POST : 정보를 밀어넣기 위해서 사용한다. (INSERT)
    * PUT : 정보를 업데이트하기 위해서 사용한다. (UPDATE)
    * DELETE : 정보를 삭제하기 위해서 사용한다. (DELETE)
    * HEAD : (HTTP)헤더 정보만 요청한다. 해당 자원이 존재하는지 혹은 서버에 문제가 없는지를 확인하기 위해서 사용한다.
    * OPTIONS : 웹서버가 지원하는 메서드의 종류를 요청한다.
    * TRACE : 클라이언트의 요청을 그대로 반환한다. 예컨데 echo 서비스로 서버 상태를 확인하기 위한 목적으로 주로 사용한다.

* haproxy
    * 성능은 초당 8만건
    * 단점: 1.4.22 버전에서는 SSL을 지원하지 않아서, apache 특정 모듈 mod_ssl을 이용해서 사용해야 했음.

* sellinux 의 용도.?

